#calculate euclidean distance between vectors/matrices/data.frames
dist=sqrt(sum((a-b)^2))
return(dist)
}
knn_prediction=function(x, y, k, x0){
#need a distance matrix, i.e. for each point in x0 have a column with
#distances to points in x (training set)
#then rank the values in each column and get the ones from 1 to k
#use the respective observations in the y vector to calculate the mean over
#them as the prediction
#set up vector in which predictions will be saved
predictions=rep(NA, length(y))
#then loop over each observation in test data
for(i in 1:length(y)){
#get euclidean distances between single row in test data and all rows
#in training data
euclid=apply(x, 1, euclid_dist, x0[i, ])
#sort them by size and get first k values -> indices that are closest ones
ranks=rank(euclid, ties.method='random')<=k
#get corresponding y values in training data and get mean as prediction
predictions[[i]]=mean(y[ranks])
}
return(predictions)
}
cv_knn_prediction=function(x, y, k_range, x0, y0){
#this function makes KNN prediction using each value in k_range as number
#of neighbors, then calculates MSE for each of them and returns predictions that
#yield smallest MSE
#create empty matrix that will be filled column wise with predictions for y
#for different k
predictions_k=matrix(NA, nrow=length(y), ncol=length(k_range))
#and empty vector in which mse will be saved
mses=rep(NA, length(k_range))
for(i in 1:length(k_range)){
#make prediction for given k
predictions_k[, i]=knn_prediction(x=x, y=y, k=k_range[[i]], x0=x0)
mses[i]=mean((y0-predictions_k[, i])^2)
}
#find index of predictions with smallest mse
lowest=which(mses==min(mses))
#get the predictions of the corresponding k
predictions_fin=predictions_k[, lowest]
#return these predictions, the min mse and the corresponding k
return(list(predictions=predictions_fin, mse=mses[lowest], k_min=k_range[lowest]))
}
visual_eval=function(data, true, preds, title){
#this function plots true values against predictions of the variable as a visual way
#of evaluation
plot=ggplot(test_preds, aes(x=true, y=preds))+
geom_point(size=0.2)+
geom_abline(color='red', size=0.1)+
labs(x='Charges', y='Prediction', title=title)
return(plot)
}
mz_test=function(true, preds){
#This function runs the Mincer-Zarnowitz Test for prediction evaluation
#first run a simple OLS regression of true values on predictions
reg=lm(true~preds)
#make a Wald test on whether the coefficients are jointly significant
coefci=coefci(reg, vcov.=NeweyWest)%>%round(3)
W=t(coef(reg)-c(0,1))%*%solve(NeweyWest(reg))%*%(coef(reg)-c(0,1))
pval=1-pchisq(W,2)%>%round(3)
return(list(ci=coefci, wald=W, pval=pval))
}
#Bergman loss function with phi(x)=x^2
sq_loss=function(true, pred){(true-pred)^2}
#Bergman loss function with phi(x)=-log(x)
log_loss=function(true, pred){loss=log(true) - log(true) + true/pred - 1}
#Bergman loss function with phi(x)=exp(-x)
exp_loss=function(true, pred){exp(-true) - exp(-pred) + exp(-pred) *(true-pred)}
dm_test=function(true, pred1, pred2, loss='squared'){
#this function runs a Diebold-Mariano Test using the loss function specified in
#loss argument
if(loss=='squared'){
d=sq_loss(true, pred1)-sq_loss(true, pred2)
reg=lm(d~1)
}
#if loss=exp use loss function with exp(-x)
else if(loss=='exp'){
d=exp_loss(true, pred1)-exp_loss(true, pred2)
reg=lm(d~1)
}
#if loss=log use QLIKE loss function which arises from using phi(x)=-log(x)
else if(loss=='log'){
d=log_loss(true, pred1)-log_loss(true, pred2)
reg=lm(d~1)
}
else{
print('Specify loss to be squared, log, or exp!')
}
#then run significane test with heteroskedastiticy robust std errors
sig_test=coefci(reg, vcov.=NeweyWest)
return(list(mean_d=mean(d), sigtest=sig_test))
}
make_compare_frame=function(comp1, comp2, comp3){
lowerbounds=c(comp1$sigtest[1], comp2$sigtest[1], comp3$sigtest[1])
upperbounds=c(comp1$sigtest[2], comp2$sigtest[2], comp3$sigtest[2])
comparison=c('KNN vs RF', 'Lasso vs RF', 'Lasso vs KNN')
return(data.frame(Methods=comparison, Lower=lowerbounds, Upper=upperbounds))
}
############
#Problem 2
############
#read in data
insurance=read.csv('insurance.csv')
#a) split data into test and training set
#same procedure as in Problem 1
test_train_data=test_train_sample(insurance, test_n=dim(insurance)[1]/2)
test_dat=test_train_data$test
train_dat=test_train_data$train
#also prepare a dataframe in which predictions and true values are saved
test_preds=test_dat%>%dplyr::select(charges)
#b) Predict mean of y=charges with 3 different prediction methods
#ASSUME THAT WE ARE TALKING ABOUT THE CONDITIONAL MEAN
#1 LASSO
#Lasso
#prepare training data: get x and interactions as well as y values as single dataframes/vectors
x_train=model.matrix(charges~.^2, data=train_dat)
y_train=train_dat$charges
#fit model using cross validation
lasso=cv.glmnet(x=x_train, y=y_train, alpha=1)
#prepare test data
x_test=model.matrix(charges~.^2, data=test_dat)
#then fit model to test data
#turn lasso predictions into vector as they are otherwise saved as a dataframe inside
#the dataframe with predictions
test_preds$lasso_preds=as.vector(predict(lasso, newx=x_test, s='lambda.1se'))
#get variables that are not removed by lasso for knn
#first get matrix of coefficients and remove intercepts
lasso_coefs=as.matrix(coef(lasso, s='lambda.1se'))[-1:-2, ]
#then extract names where coefficient is not 0
lasso_vars=names(lasso_coefs)[lasso_coefs!=0]
#2 Random Forest
#fit a random forest to training data
rf=randomForest(charges~., data=train_dat)
#then make predictions
test_preds$rf_preds=predict(rf, newdata=test_dat)
rf$importance
sort(rf$importance)
order(rf$importance)
y_train=train_dat$charges
y_test=test_dat$charges
x_train=model.matrix(charges~.^2, data=train_dat)[, c('age', 'bmi', 'children', 'smokeryes')]
x_test=model.matrix(charges~.^2, data=test_dat)[, c('age', 'bmi', 'children', 'smokeryes')]
knn=knn_cv(x_train, y_train, x_test, y_test, max_k=15)
rm(list=ls())
setwd("/Users/llccf/OneDrive/Dokumente/4. Semester/PredictiveModeling/exam/")
#also set seed so replications of this code generate same results
set.seed(2021)
test_train_sample=function(dat, test_n=1000){
#split a sample in dat into a test and training sample
#test_n defines size of test sample created
#rownames are reset to avoid confusion between them and indices
#create slicing
slices=sample.int(nrow(dat), size=test_n)
#create subsets
train=dat[-slices, ]
test=dat[slices, ]
#return them in a named list
dat_list=list('train'=train, 'test'=test)
return (dat_list)
}
euclidean <- function(a, b){
return(sqrt(sum((a-b)^2)))
}
knn_prediction=function(x, y, k, x0){
# set up vector in which predictions are saved
predictions=rep(NA, dim(x0)[1])
for(i in 1:dim(x0)[1]){
# Get the rank of the absolute deviation compared to training data
dist=apply(x, 1, euclidean, x0[i, ])
ranks=rank(dist, ties.method = "random")
# Indices of outcome variable where rank is sufficiently close
nearest=ranks<=k
predictions[i] = mean(y[nearest])
}
return(predictions)
}
predict_knn <- function(x, y, k, x0_single){
# Get the rank of the absolute deviation compared to training data
dist <- apply(x, 1, euclidean, x0_single)
rank_vec <- rank(dist, ties.method = "random")
# Indices of outcome variable where rank is sufficiently close
neighbor_indices <- rank_vec <= k
# Return the mean of those neighboring Y-values
return(mean(y[neighbor_indices]))
}
kNN_prediction <- function(x, y, k, x0){
# Making sure that input lengths are the same
stopifnot(dim(x)[1]==length(y))
# Allocating space
result_arr <- array(numeric(), dim(x0)[1])
for(i in 1:dim(x0)[1]){
result_arr[i] = predict_knn(x, y, k, x0[i,])
}
return(result_arr)
}
knn_cv=function(x_train, y_train, x_test, y_test, max_k){
#make empty matrix in which predictions are saved
predictions_k=matrix(nrow=length(y_test), ncol=max_k)
#save MSEs of this prediction
mses=rep(NA, max_k)
for (i in 1:max_k){
#get predicitons for given k
predictions_k[, i]=knn_prediction(x_train, y_train, k=i, x_test)
#calculate mse of these
mses[i]=mean(((y_test-predictions_k[, i])^2))
}
#find index of smallest MSE
lowest=which(mses==min(mses))
#get the corresponding predictions
pred_fin=predictions_k[, lowest]
return(pred_fin)
}
insurance=read.csv('insurance.csv')
test_train_dat=test_train_sample(insurance, test_n=dim(insurance)%/%2)
test_dat=test_train_dat$test
train_dat=test_train_dat$train
y_train=train_dat$charges
y_test=test_dat$charges
x_train=model.matrix(charges~.^2, data=train_dat)[, c('age', 'bmi', 'children', 'smokeryes')]
x_test=model.matrix(charges~.^2, data=test_dat)[, c('age', 'bmi', 'children', 'smokeryes')]
knn=knn_cv(x_train, y_train, x_test, y_test, max_k=15)
mean((y_test-knn)^2)
rm(list=ls())
setwd("/Users/llccf/OneDrive/Dokumente/4. Semester/PredictiveModeling/exam/")
#also set seed so replications of this code generate same results
set.seed(2021)
test_train_sample=function(dat, test_n=1000){
#split a sample in dat into a test and training sample
#test_n defines size of test sample created
#rownames are reset to avoid confusion between them and indices
#create slicing
slices=sample.int(nrow(dat), size=test_n)
#create subsets
train=dat[-slices, ]
test=dat[slices, ]
#return them in a named list
dat_list=list('train'=train, 'test'=test)
return (dat_list)
}
euclidean <- function(a, b){
return(sqrt(sum((a-b)^2)))
}
knn_prediction=function(x, y, k, x0){
# set up vector in which predictions are saved
predictions=rep(NA, dim(x0)[1])
for(i in 1:dim(x0)[1]){
# Get the rank of the absolute deviation compared to training data
dist=apply(x, 1, euclidean, x0[i, ])
ranks=rank(dist, ties.method = "random")
# Indices of outcome variable where rank is sufficiently close
nearest=ranks<=k
predictions[i] = mean(y[nearest])
}
return(predictions)
}
predict_knn <- function(x, y, k, x0_single){
# Get the rank of the absolute deviation compared to training data
dist <- apply(x, 1, euclidean, x0_single)
rank_vec <- rank(dist, ties.method = "random")
# Indices of outcome variable where rank is sufficiently close
neighbor_indices <- rank_vec <= k
# Return the mean of those neighboring Y-values
return(mean(y[neighbor_indices]))
}
kNN_prediction <- function(x, y, k, x0){
# Making sure that input lengths are the same
stopifnot(dim(x)[1]==length(y))
# Allocating space
result_arr <- array(numeric(), dim(x0)[1])
for(i in 1:dim(x0)[1]){
result_arr[i] = predict_knn(x, y, k, x0[i,])
}
return(result_arr)
}
knn_cv=function(x_train, y_train, x_test, y_test, max_k){
#make empty matrix in which predictions are saved
predictions_k=matrix(nrow=length(y_test), ncol=max_k)
#save MSEs of this prediction
mses=rep(NA, max_k)
for (i in 1:max_k){
#get predicitons for given k
predictions_k[, i]=knn_prediction(x_train, y_train, k=i, x_test)
#calculate mse of these
mses[i]=mean(((y_test-predictions_k[, i])^2))
}
#find index of smallest MSE
lowest=which(mses==min(mses))
#get the corresponding predictions
pred_fin=predictions_k[, lowest]
return(pred_fin)
}
### DATA
insurance=read.csv('insurance.csv')
test_train_dat=test_train_sample(insurance, test_n=dim(insurance)%/%2)
test_dat=test_train_dat$test
train_dat=test_train_dat$train
y_train=train_dat$charges
y_test=test_dat$charges
x_train=model.matrix(charges~.^2, data=train_dat)[, c('bmi:smokeryes', 'age:smokeryes',
'smokeryes', 'age:bmi', 'bmi')]
x_test=model.matrix(charges~.^2, data=test_dat)[, c('bmi:smokeryes', 'age:smokeryes',
'smokeryes', 'age:bmi', 'bmi')]
knn=knn_cv(x_train, y_train, x_test, y_test, 15)
mean((y_test-knn)^2)
#get most important feature in rf based on node purity increase
importance_df=data.frame(rf$importance)
rm(list=ls())
library(ggplot2)
library(randomForest)
library(tree)
library(dplyr)
library(glmnet)
library(reshape2)
library(plotROC)
library(reliabilitydiag)
library(murphydiagram)
library(quantreg)
library(lmtest)
library(sandwich)
#set working directory to data path
setwd("/Users/llccf/OneDrive/Dokumente/4. Semester/PredictiveModeling/exam/")
#also set seed so replications of this code generate same results
set.seed(2021)
############
#Functions
############
#This section contains all functions defined for the problems solved in their respective section.
#Comments within the functions explain what is going on in there and whenever applied referenced
#in the comments.
test_train_sample=function(dat, test_n=1000){
#split a sample in dat into a test and training sample
#test_n defines size of test sample created
#rownames are reset to avoid confusion between them and indices
#create slicing
slices=sample.int(nrow(dat), size=test_n)
#create subsets
train=dat[-slices, ]
rownames(train)=NULL
test=dat[slices, ]
rownames(test)=NULL
#return them in a named list
dat_list=list('train'=train, 'test'=test)
return (dat_list)
}
#reuse functions from PS2 for KNN predictions
euclid_dist=function(a, b){
#calculate euclidean distance between vectors/matrices/data.frames
dist=sqrt(sum((a-b)^2))
return(dist)
}
knn_prediction=function(x, y, k, x0){
#need a distance matrix, i.e. for each point in x0 have a column with
#distances to points in x (training set)
#then rank the values in each column and get the ones from 1 to k
#use the respective observations in the y vector to calculate the mean over
#them as the prediction
#set up vector in which predictions will be saved
predictions=rep(NA, length(y))
#then loop over each observation in test data
for(i in 1:length(y)){
#get euclidean distances between single row in test data and all rows
#in training data
euclid=apply(x, 1, euclid_dist, x0[i, ])
#sort them by size and get first k values -> indices that are closest ones
ranks=rank(euclid, ties.method='random')<=k
#get corresponding y values in training data and get mean as prediction
predictions[[i]]=mean(y[ranks])
}
return(predictions)
}
cv_knn_prediction=function(x, y, k_range, x0, y0){
#this function makes KNN prediction using each value in k_range as number
#of neighbors, then calculates MSE for each of them and returns predictions that
#yield smallest MSE
#create empty matrix that will be filled column wise with predictions for y
#for different k
predictions_k=matrix(NA, nrow=length(y), ncol=length(k_range))
#and empty vector in which mse will be saved
mses=rep(NA, length(k_range))
for(i in 1:length(k_range)){
#make prediction for given k
predictions_k[, i]=knn_prediction(x=x, y=y, k=k_range[[i]], x0=x0)
mses[i]=mean((y0-predictions_k[, i])^2)
}
#find index of predictions with smallest mse
lowest=which(mses==min(mses))
#get the predictions of the corresponding k
predictions_fin=predictions_k[, lowest]
#return these predictions, the min mse and the corresponding k
return(list(predictions=predictions_fin, mse=mses[lowest], k_min=k_range[lowest]))
}
visual_eval=function(data, true, preds, title){
#this function plots true values against predictions of the variable as a visual way
#of evaluation
plot=ggplot(test_preds, aes(x=true, y=preds))+
geom_point(size=0.2)+
geom_abline(color='red', size=0.1)+
labs(x='Charges', y='Prediction', title=title)
return(plot)
}
mz_test=function(true, preds){
#This function runs the Mincer-Zarnowitz Test for prediction evaluation
#first run a simple OLS regression of true values on predictions
reg=lm(true~preds)
#make a Wald test on whether the coefficients are jointly significant
coefci=coefci(reg, vcov.=NeweyWest)%>%round(3)
W=t(coef(reg)-c(0,1))%*%solve(NeweyWest(reg))%*%(coef(reg)-c(0,1))
pval=1-pchisq(W,2)%>%round(3)
return(list(ci=coefci, wald=W, pval=pval))
}
#Bergman loss function with phi(x)=x^2
sq_loss=function(true, pred){(true-pred)^2}
#Bergman loss function with phi(x)=-log(x)
log_loss=function(true, pred){loss=log(true) - log(true) + true/pred - 1}
#Bergman loss function with phi(x)=exp(-x)
exp_loss=function(true, pred){exp(-true) - exp(-pred) + exp(-pred) *(true-pred)}
dm_test=function(true, pred1, pred2, loss='squared'){
#this function runs a Diebold-Mariano Test using the loss function specified in
#loss argument
if(loss=='squared'){
d=sq_loss(true, pred1)-sq_loss(true, pred2)
reg=lm(d~1)
}
#if loss=exp use loss function with exp(-x)
else if(loss=='exp'){
d=exp_loss(true, pred1)-exp_loss(true, pred2)
reg=lm(d~1)
}
#if loss=log use QLIKE loss function which arises from using phi(x)=-log(x)
else if(loss=='log'){
d=log_loss(true, pred1)-log_loss(true, pred2)
reg=lm(d~1)
}
else{
print('Specify loss to be squared, log, or exp!')
}
#then run significane test with heteroskedastiticy robust std errors
sig_test=coefci(reg, vcov.=NeweyWest)
return(list(mean_d=mean(d), sigtest=sig_test))
}
make_compare_frame=function(comp1, comp2, comp3){
lowerbounds=c(comp1$sigtest[1], comp2$sigtest[1], comp3$sigtest[1])
upperbounds=c(comp1$sigtest[2], comp2$sigtest[2], comp3$sigtest[2])
comparison=c('KNN vs RF', 'Lasso vs RF', 'Lasso vs KNN')
return(data.frame(Methods=comparison, Lower=lowerbounds, Upper=upperbounds))
}
############
#Problem 2
############
#read in data
insurance=read.csv('insurance.csv')
#a) split data into test and training set
#same procedure as in Problem 1
test_train_data=test_train_sample(insurance, test_n=dim(insurance)[1]/2)
test_dat=test_train_data$test
train_dat=test_train_data$train
#also prepare a dataframe in which predictions and true values are saved
test_preds=test_dat%>%dplyr::select(charges)
#b) Predict mean of y=charges with 3 different prediction methods
#ASSUME THAT WE ARE TALKING ABOUT THE CONDITIONAL MEAN
#1 LASSO
#Lasso
#prepare training data: get x and interactions as well as y values as single dataframes/vectors
x_train=model.matrix(charges~.^2, data=train_dat)
y_train=train_dat$charges
#fit model using cross validation
lasso=cv.glmnet(x=x_train, y=y_train, alpha=1)
#prepare test data
x_test=model.matrix(charges~.^2, data=test_dat)
#then fit model to test data
#turn lasso predictions into vector as they are otherwise saved as a dataframe inside
#the dataframe with predictions
test_preds$lasso_preds=as.vector(predict(lasso, newx=x_test, s='lambda.1se'))
#get variables that are not removed by lasso for knn
#first get matrix of coefficients and remove intercepts
lasso_coefs=as.matrix(coef(lasso, s='lambda.1se'))[-1:-2, ]
#then extract names where coefficient is not 0
lasso_vars=names(lasso_coefs)[lasso_coefs!=0]
#2 Random Forest
#fit a random forest to training data
rf=randomForest(charges~., data=train_dat)
#then make predictions
test_preds$rf_preds=predict(rf, newdata=test_dat)
#get most important feature in rf based on node purity increase
importance_df=data.frame(rf$importance)
importance_df
#get most important feature in rf based on node purity increase
importance_df=data.frame(rf$importance)%>%mutate(variable=rownames())
#get most important feature in rf based on node purity increase
importance_df=data.frame(rf$importance)%>%mutate(variable=rownames(.))
importance_df
most_important_rf=function(rf){
#get most important variable in rf based on node purity increase
importance_df=data.frame(rf$importance)%>%mutate(variable=rownames(.))
#get name of most important variable
mi_var=importance_df[which(importance_df['IncNodePurity']==min(importance_df['IncNodePurity'])),
'variable']
return(mi_var)
}
most_important_rf(rf)
most_important_rf=function(rf){
#get most important variable in rf based on node purity increase
importance_df=data.frame(rf$importance)%>%mutate(variable=rownames(.))
#get name of most important variable
mi_var=importance_df[which(importance_df['IncNodePurity']==max(importance_df['IncNodePurity'])),
'variable']
return(mi_var)
}
test='age'
get(age)
